# ğŸ§  Sentiric LLM Local Service

**Sentiric LLM Local Service**, yerel donanÄ±m Ã¼zerinde (on-premise) BÃ¼yÃ¼k Dil Modeli (LLM) Ã§Ä±karÄ±mÄ± saÄŸlayan uzman bir AI motorudur. `CTranslate2` kÃ¼tÃ¼phanesini kullanarak, `Phi-3`, `Llama3` gibi popÃ¼ler aÃ§Ä±k kaynaklÄ± modelleri GPU veya CPU Ã¼zerinde optimize bir ÅŸekilde Ã§alÄ±ÅŸtÄ±rÄ±r.

Bu servis, `llm-gateway-service` tarafÄ±ndan, dÃ¼ÅŸÃ¼k gecikmeli, gÃ¼venli veya maliyet-etkin metin Ã¼retimi ihtiyaÃ§larÄ± iÃ§in Ã§aÄŸrÄ±lÄ±r.

## ğŸ¯ Temel Sorumluluklar

-   **Yerel Ã‡Ä±karÄ±m:** Harici API'lere ihtiyaÃ§ duymadan LLM modellerini Ã§alÄ±ÅŸtÄ±rÄ±r.
-   **YÃ¼ksek Performans:** `CTranslate2` sayesinde optimize edilmiÅŸ ve kuantize edilmiÅŸ model Ã§Ä±karÄ±mÄ±.
-   **gRPC Streaming:** Metin yanÄ±tlarÄ±nÄ± token token Ã¼reterek dÃ¼ÅŸÃ¼k algÄ±lanan gecikme saÄŸlar.
-   **DonanÄ±m HÄ±zlandÄ±rma:** NVIDIA GPU (CUDA) ve CPU iÃ§in destek.
-   **Dinamik SaÄŸlÄ±k KontrolÃ¼:** Modelin yÃ¼klenip hazÄ±r olup olmadÄ±ÄŸÄ±nÄ± bildiren `/health` endpoint'i.
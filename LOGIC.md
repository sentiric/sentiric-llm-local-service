#  Sentiric LLM Local Service - Mant覺k ve Ak覺

**Stratejik Rol:** Platformun "Dijital Egemenlik" felsefesine uygun olarak, d覺 bulut servislerine ba覺ml覺 olmadan, yerel donan覺m (CPU/GPU) 羹zerinde y羹ksek performansl覺 metin 羹retimi (LLM) yetenei sunan uzman AI motorudur. Genellikle `llm-gateway-service` taraf覺ndan 癟ar覺l覺r.

## Temel Ak覺: Token Streaming

Servisin ana g繹revi, bir `prompt` al覺p, 羹retilen metni anl覺k olarak token token geri g繹ndermektir.

```mermaid
sequenceDiagram
    participant Gateway as LLM Gateway
    participant LocalLLM as LLM Local Service
    participant CTranslate2 as CTranslate2 Engine

    Gateway->>+LocalLLM: gRPC: LocalGenerateStream(prompt)
    
    LocalLLM->>+CTranslate2: generate_tokens(prompt_tokens)
    
    loop Token retimi
        CTranslate2-->>LocalLLM: Bir sonraki token
        LocalLLM-->>-Gateway: gRPC stream: token
    end
    
    deactivate CTranslate2
    deactivate LocalLLM
```
 
---